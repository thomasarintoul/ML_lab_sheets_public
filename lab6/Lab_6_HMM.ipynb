{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Hidden Markov Model\n",
    "\n",
    "\n",
    "In this lab we will look into Hidden Markov Models (HMM) to model sequential data. HMMs use Markov Chains to compute probabilities for a sequence of observed events. Moreover, HMMs are based on the Markov assumption, which states that the present state $z_n$ is sufficient to predict the future $z_{n+1}$, so the past $z_{0:n-1}$ can be discarded.\n",
    "\n",
    "<img src=\"hmm.png\" width=\"400\">\n",
    "\n",
    "Often, we are in a situation where the states we are interested in are hidden, we cannot observe them directly. As we will see in Exercise 2, the part-of-speech (POS) tags in a text are hidden and we can only observe the words. From these words we have to infer the tags. Similarly in Exercises 3 where a robot needs to be localised, we cannot observe the robot's position but rather the measurements of its sensors. Both the tags and the robot position are called hidden variables because they are not observed.\n",
    "An HMM is specified by the following components:\n",
    "\n",
    "* A set of $N$ states.\n",
    "\n",
    "* A transition probability matrix $A$ where each element $a_{ij}$ represents the probability of moving from state $i$ to state $j$, s.t.  $ \\sum^{N}_{j=1} a_{ij} = 1$ $ \\forall i$\n",
    "\n",
    "* An emission probability distribution, the probabilities of observations $x_n$ being generated from a state $z_n$\n",
    "\n",
    "* An initial probability distribution over states. $\\pi_n$ is the probability that the Markov chain will start in state $n$. Also, $\\sum^{N}_{n=1} \\pi_n = 1 $\n",
    "\n",
    "\n",
    "### Additional packages\n",
    "\n",
    "For this lab we need `hmmlearn`, `nltk`, `ipywidgets` which you can install with conda:\n",
    "\n",
    "```python\n",
    "conda install -c conda-forge hmmlearn\n",
    "conda install -c anaconda nltk\n",
    "conda install -c conda-forge ipywidgets\n",
    "```\n",
    "\n",
    "Let's import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:25.815669500Z",
     "start_time": "2024-02-01T15:37:25.697750100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from IPython import display\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import ConditionalFreqDist,ConditionalProbDist,MLEProbDist\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# interactive display\n",
    "import ipywidgets as widgets\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) HMM with 2 states\n",
    "We will start with a warm up exercise where you have to implement an HMM with 2 states and then analyse how the transition probability and emission noise influence the output. Your task is to create a function `hmm_model` that has three arguments:\n",
    "1. `switch_prob`: The probability of switching to the other state.\n",
    "2. `noise_level`: The variance of the emission distribution, i.e. the measurement/observation noise.\n",
    "3. `startprob`: The probabilities of starting in each state (`shape=(2,1)`).\n",
    "\n",
    "Your function should create a [hmm.GaussianHMM](https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.GaussianHMM) model with two states (hidden states) and `covariance_type=\"full\"`. Modify the following model attributes:\n",
    "* `startprob_`: Using the `startprob` argument.\n",
    "* `transmat_`: Implement a transition matrix with probability of transition for both states being $p_{transition} = $ `switch_prob`.\n",
    "* `means_`: Add mean $\\mu_1 = 1$ and $\\mu_2 = -1$ for each state\n",
    "* `covars_`: Using the the `noise_level` argument. (note: the shape should be `(2, 1, 1)`, i.e. two $1\\times1$ covariance matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:25.838924Z",
     "start_time": "2024-02-01T15:37:25.819177400Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_hmm(model, states, observations):\n",
    "    \"\"\"Plots HMM states and observations for 1d states and observations.\n",
    "\n",
    "    Args:\n",
    "    model (hmmlearn model):               hmmlearn model used to get state means.\n",
    "    states (numpy array of floats):       Samples of the states.\n",
    "    observations (numpy array of floats): Samples of the states.\n",
    "    \"\"\"\n",
    "\n",
    "    nsteps = states.size\n",
    "    fig, ax1 = plt.subplots(figsize=(6,3))\n",
    "    states_forplot = list(map(lambda s: model.means_[s], states))\n",
    "    ax1.step(np.arange(nstep), states_forplot, \"--\", where=\"mid\", alpha=1.0, c=\"green\")\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "    ax1.set_ylabel(\"Latent State\", c=\"green\")\n",
    "    ax1.set_yticks([-1, 1])\n",
    "    ax1.set_yticklabels([\"State 1\", \"State 0\"])\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(np.arange(nstep), observations.flatten(), c=\"blue\")\n",
    "    ax2.set_ylabel(\"Observations\", c=\"blue\")\n",
    "    ax1.set_ylim(ax2.get_ylim())\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:25.869700900Z",
     "start_time": "2024-02-01T15:37:25.826689700Z"
    }
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def hmm_model(switch_prob, noise_level, startprob):\n",
    "    n_components = 2\n",
    "    \n",
    "    hmm_mod = hmm.GaussianHMM(n_components=2, covariance_type=\"full\")\n",
    "    hmm_mod.startprob_ = startprob\n",
    "    hmm_mod.transmat_ = np.array([[switch_prob, 1. - switch_prob],\n",
    "                                 [1. - switch_prob, switch_prob]])\n",
    "    hmm_mod.means_ = np.array([[1.0], [-1.0]])\n",
    "    hmm_mod.covars_ = np.ones((2,1,1)) * noise_level\n",
    "    \n",
    "    return hmm_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, execute the cell below to run your `hmm_model` and visualise the output with the provided `plot_hmm` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:25.965506700Z",
     "start_time": "2024-02-01T15:37:25.840930200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x300 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"450.85pt\" height=\"211.07625pt\" viewBox=\"0 0 450.85 211.07625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-02-01T15:37:25.908820</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 211.07625 \nL 450.85 211.07625 \nL 450.85 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 63.889063 173.52 \nL 398.689063 173.52 \nL 398.689063 7.2 \nL 63.889063 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mbc743d3cd8\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"79.107244\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(75.925994 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"141.222272\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(134.859772 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"203.3373\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(196.9748 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"265.452328\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(259.089828 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"327.567356\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(321.204856 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mbc743d3cd8\" x=\"389.682383\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(383.319883 188.118438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Time -->\n     <g transform=\"translate(219.055469 201.796563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"57.958984\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"85.742188\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"183.154297\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m4732553e67\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m4732553e67\" x=\"63.889063\" y=\"165.939508\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- State 1 -->\n      <g transform=\"translate(20.878125 169.738727) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"63.476562\"/>\n       <use xlink:href=\"#DejaVuSans-61\" x=\"102.685547\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"163.964844\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"203.173828\"/>\n       <use xlink:href=\"#DejaVuSans-20\" x=\"264.697266\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"296.484375\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m4732553e67\" x=\"63.889063\" y=\"14.772172\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- State 0 -->\n      <g transform=\"translate(20.878125 18.571391) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"63.476562\"/>\n       <use xlink:href=\"#DejaVuSans-61\" x=\"102.685547\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"163.964844\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"203.173828\"/>\n       <use xlink:href=\"#DejaVuSans-20\" x=\"264.697266\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"296.484375\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Latent State -->\n     <g style=\"fill: #008000\" transform=\"translate(14.798438 121.199844) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"55.712891\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"116.992188\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"156.201172\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"217.724609\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"281.103516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"320.3125\"/>\n      <use xlink:href=\"#DejaVuSans-53\" x=\"352.099609\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"415.576172\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"454.785156\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"516.064453\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"555.273438\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_9\">\n    <path d=\"M 79.107244 14.772172 \nL 82.212996 14.772172 \nL 82.212996 165.939508 \nL 88.424498 165.939508 \nL 88.424498 14.772172 \nL 94.636001 14.772172 \nL 94.636001 165.939508 \nL 100.847504 165.939508 \nL 100.847504 14.772172 \nL 107.059007 14.772172 \nL 107.059007 165.939508 \nL 113.27051 165.939508 \nL 113.27051 14.772172 \nL 119.482012 14.772172 \nL 119.482012 165.939508 \nL 125.693515 165.939508 \nL 125.693515 14.772172 \nL 131.905018 14.772172 \nL 131.905018 165.939508 \nL 138.116521 165.939508 \nL 138.116521 14.772172 \nL 144.328024 14.772172 \nL 144.328024 165.939508 \nL 150.539526 165.939508 \nL 150.539526 14.772172 \nL 156.751029 14.772172 \nL 156.751029 165.939508 \nL 162.962532 165.939508 \nL 162.962532 165.939508 \nL 169.174035 165.939508 \nL 169.174035 14.772172 \nL 175.385537 14.772172 \nL 175.385537 165.939508 \nL 181.59704 165.939508 \nL 181.59704 14.772172 \nL 187.808543 14.772172 \nL 187.808543 165.939508 \nL 194.020046 165.939508 \nL 194.020046 14.772172 \nL 200.231549 14.772172 \nL 200.231549 165.939508 \nL 206.443051 165.939508 \nL 206.443051 14.772172 \nL 212.654554 14.772172 \nL 212.654554 165.939508 \nL 218.866057 165.939508 \nL 218.866057 14.772172 \nL 225.07756 14.772172 \nL 225.07756 14.772172 \nL 231.289062 14.772172 \nL 231.289062 165.939508 \nL 237.500565 165.939508 \nL 237.500565 14.772172 \nL 243.712068 14.772172 \nL 243.712068 165.939508 \nL 249.923571 165.939508 \nL 249.923571 165.939508 \nL 256.135074 165.939508 \nL 256.135074 14.772172 \nL 262.346576 14.772172 \nL 262.346576 165.939508 \nL 268.558079 165.939508 \nL 268.558079 14.772172 \nL 274.769582 14.772172 \nL 274.769582 165.939508 \nL 280.981085 165.939508 \nL 280.981085 14.772172 \nL 287.192588 14.772172 \nL 287.192588 165.939508 \nL 293.40409 165.939508 \nL 293.40409 14.772172 \nL 299.615593 14.772172 \nL 299.615593 165.939508 \nL 305.827096 165.939508 \nL 305.827096 14.772172 \nL 312.038599 14.772172 \nL 312.038599 165.939508 \nL 318.250101 165.939508 \nL 318.250101 14.772172 \nL 324.461604 14.772172 \nL 324.461604 14.772172 \nL 330.673107 14.772172 \nL 330.673107 165.939508 \nL 336.88461 165.939508 \nL 336.88461 14.772172 \nL 343.096113 14.772172 \nL 343.096113 165.939508 \nL 349.307615 165.939508 \nL 349.307615 14.772172 \nL 355.519118 14.772172 \nL 355.519118 165.939508 \nL 361.730621 165.939508 \nL 361.730621 14.772172 \nL 367.942124 14.772172 \nL 367.942124 165.939508 \nL 374.153627 165.939508 \nL 374.153627 165.939508 \nL 380.365129 165.939508 \nL 380.365129 165.939508 \nL 383.470881 165.939508 \n\" clip-path=\"url(#p3cf75d8c60)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 63.889063 173.52 \nL 63.889063 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 398.689063 173.52 \nL 398.689063 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 63.889063 173.52 \nL 398.689062 173.52 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 63.889063 7.2 \nL 398.689062 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m8454e3188e\" d=\"M 0 0 \nL 3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8454e3188e\" x=\"398.689063\" y=\"165.939508\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −1.0 -->\n      <g transform=\"translate(405.689063 169.738727) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m8454e3188e\" x=\"398.689063\" y=\"128.147674\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −0.5 -->\n      <g transform=\"translate(405.689063 131.946893) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m8454e3188e\" x=\"398.689063\" y=\"90.35584\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.0 -->\n      <g transform=\"translate(405.689063 94.155059) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m8454e3188e\" x=\"398.689063\" y=\"52.564006\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.5 -->\n      <g transform=\"translate(405.689063 56.363225) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m8454e3188e\" x=\"398.689063\" y=\"14.772172\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g transform=\"translate(405.689063 18.571391) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Observations -->\n     <g style=\"fill: #0000ff\" transform=\"translate(441.570312 123.412344) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4f\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"78.710938\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"142.1875\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"194.287109\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"255.810547\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"296.923828\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"356.103516\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"417.382812\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"456.591797\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"484.375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"545.556641\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"608.935547\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 79.107244 14.775432 \nL 85.318747 165.939019 \nL 91.53025 14.776027 \nL 97.741753 165.93284 \nL 103.953255 14.770401 \nL 110.164758 165.949638 \nL 116.376261 14.773443 \nL 122.587764 165.940325 \nL 128.799267 14.765068 \nL 135.010769 165.948086 \nL 141.222272 14.774236 \nL 147.433775 165.941896 \nL 153.645278 14.760161 \nL 159.85678 165.935478 \nL 166.068283 165.942512 \nL 172.279786 14.762636 \nL 178.491289 165.93284 \nL 184.702792 14.775028 \nL 190.914294 165.937181 \nL 197.125797 14.776759 \nL 203.3373 165.932559 \nL 209.548803 14.781213 \nL 215.760306 165.92431 \nL 221.971808 14.773213 \nL 228.183311 14.769204 \nL 234.394814 165.950405 \nL 240.606317 14.77391 \nL 246.817819 165.94921 \nL 253.029322 165.96 \nL 259.240825 14.783679 \nL 265.452328 165.930959 \nL 271.663831 14.768404 \nL 277.875333 165.925509 \nL 284.086836 14.778916 \nL 290.298339 165.927021 \nL 296.509842 14.770684 \nL 302.721345 165.930957 \nL 308.932847 14.763965 \nL 315.14435 165.944407 \nL 321.355853 14.779399 \nL 327.567356 14.76 \nL 333.778858 165.929534 \nL 339.990361 14.774921 \nL 346.201864 165.931332 \nL 352.413367 14.76314 \nL 358.62487 165.931371 \nL 364.836372 14.777905 \nL 371.047875 165.942945 \nL 377.259378 165.9297 \nL 383.470881 165.945746 \n\" clip-path=\"url(#p3cf75d8c60)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 63.889063 173.52 \nL 63.889063 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 398.689063 173.52 \nL 398.689063 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 63.889063 173.52 \nL 398.689062 173.52 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 63.889063 7.2 \nL 398.689062 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3cf75d8c60\">\n   <rect x=\"63.889063\" y=\"7.2\" width=\"334.8\" height=\"166.32\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(101)\n",
    "nstep = 50\n",
    "model = hmm_model(switch_prob=0.1, noise_level=1e-8, startprob=np.array([1.0, 0.0]))\n",
    "observations, states = model.sample(nstep)\n",
    "plot_hmm(model, states, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below and experiment with the interactive widget window. Try changing the value of `switch_prob` and `noise_level`, how does that changes the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:26.059551600Z",
     "start_time": "2024-02-01T15:37:25.950947400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(FloatSlider(value=0.5, description='switch_prob', max=1.0, step=0.01), FloatSlider(value…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dfb8c1c705741dd9d3e38f35f9ce257"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "#@markdown Make sure you execute this cell to enable the widget!\n",
    "np.random.seed(101)\n",
    "nstep = 50\n",
    "\n",
    "@widgets.interact\n",
    "def plot(switch_prob=(0., 1, .01), log10_noise_level=(-8., 1., .01)):\n",
    "    model = hmm_model(switch_prob=switch_prob,\n",
    "                    noise_level=10.**log10_noise_level,\n",
    "                    startprob=[1.0, 0.0])\n",
    "\n",
    "    observations, states = model.sample(nstep)\n",
    "    observations = observations.flatten()\n",
    "    plot_hmm(model, states, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) HMM Part-of-Speech Tagging\n",
    "\n",
    "Part-of-speech (POS) tagging enables the extraction of meaningful information about words in a sentence and their relation to neighbouring words. Knowing whether a word is a noun or a verb provides us information about their most likely neighboring words (such as nouns are preceded by determiners and adjectives, verbs by nouns) and syntactic structure (nouns are generally part of noun phrases), making POS tagging a key aspect of parsing. Parts of speech are useful features for labeling named entities like people or organisations in information extraction, or for coreference resolution. A word’s part of speech can even play a role in speech recognition or synthesis, e.g., the word content is pronounced CONtent when it is a noun and conTENT when it is an adjective.\n",
    "\n",
    "Part-of-speech tagging is the process of assigning a POS tag to each word in a given text. The input to a tagging algorithm is a sequence of tokenised words and the output is a sequence of tags, one per token. Particularly, words are ambiguous as they have more than one possible POS and the goal is to find the correct tag for each situation.\n",
    "For example, \"book\" can be a verb (\"book that flight\") or a noun (\"hand me that book\"). The goal of POS-tagging is to resolve these ambiguities, choosing the proper tag for the context.\n",
    "\n",
    "\n",
    "In this section we introduce the use of the Hidden Markov Model for part-of-speech tagging. The HMM can be used as a sequence tagger to assign a tag or class label to each unit in an observed sequence, thus mapping a sequence of observations to a sequence of labels. A HMM is a probabilistic sequence model: given a sequence of units (words, letters, morphemes, sentences), it computes a probability distribution over possible sequences of labels and chooses the best label sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Brown corpus dataset\n",
    "The Brown corpus is a common dataset in Natural Language Processing (NLP), it is available from the NLTK library and it supports POS tagged information. Run the cell below to download the dataset and the universal tagset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:44:01.987553500Z",
     "start_time": "2024-02-01T15:44:01.975523800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brown dataset\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the dataset and split it into training and testing.\n",
    "Run the following cells to achieve that and to prepare the dataset in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:45:46.119016500Z",
     "start_time": "2024-02-01T15:45:42.603732800Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk_data = list(brown.tagged_sents(tagset='universal'))\n",
    "train_set,test_set = train_test_split(nltk_data,\n",
    "                                      train_size=0.80,\n",
    "                                      test_size=0.20,\n",
    "                                      random_state=101\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:45:46.551758500Z",
     "start_time": "2024-02-01T15:45:46.401658100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tagged words in the training set: 927092\n",
      "Number of tagged words in the test set: 234100\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "print(f'Number of tagged words in the training set: {len(train_tagged_words)}')\n",
    "print(f'Number of tagged words in the test set: {len(test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the different types of tags by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:46:05.967736800Z",
     "start_time": "2024-02-01T15:46:05.858795900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible tags: 12\n",
      "Possible tags: {'PRON', 'VERB', 'ADV', 'X', 'ADJ', '.', 'CONJ', 'NUM', 'NOUN', 'DET', 'PRT', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "tags = {tag for word, tag in train_tagged_words}\n",
    "print(f'Number of possible tags: {len(tags)}')\n",
    "print(f'Possible tags: {tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell, explores the structure of the dataset in terms of words and sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:46:08.362598600Z",
     "start_time": "2024-02-01T15:46:08.345991700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words example: [('A', 'DET'), ('Newfoundland', 'NOUN'), ('sat', 'VERB'), ('solemnly', 'ADV'), ('beside', 'ADP')]\n",
      "Sentence example: [('A', 'DET'), ('Newfoundland', 'NOUN'), ('sat', 'VERB'), ('solemnly', 'ADV'), ('beside', 'ADP'), ('a', 'DET'), ('doghouse', 'NOUN'), ('half', 'PRT'), ('his', 'DET'), ('size', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print('Words example: {}'.format(train_tagged_words[0:5]))\n",
    "print('Sentence example: {}'.format(train_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) POS tagging model\n",
    "\n",
    "Two of the main components of HMMs are the transition model and the emission model. You already got a taste of how the two models operate in the exercise 1. Your task now is two implement both models for POS tagging model.\n",
    "\n",
    "Specifically, the transition model $P(tag_{t+1}|tag_t)$ will estimate the probability of the next tag given the current tag while the emission model $P(word|tag_t)$ will estimate the probability of observing a word given the current tag.\n",
    "\n",
    "Note: the provided hints link to the `ntlk.probability` functions, however you are free to use any other libraries such as `numpy`.\n",
    "\n",
    "#### 2.2.1) Emission Model\n",
    "Given the tagged words, the main steps are:\n",
    "1. Create a list of tuples ($tag, word$) from the input `words` which will be utilised in step 2. (careful: `words` contains tuples of ($word, tag$))\n",
    "2. Calculate the frequency for each word given the corresponding tag. (hint: [ConditionalFreqDist](https://www.nltk.org/api/nltk.html?highlight=conditionalfreqdist#nltk.probability.ConditionalFreqDist)) \n",
    "3. Calculate the conditional probability distribution given the frequency distribution of step 2. (hint: [ConditionalProbDist](https://www.nltk.org/api/nltk.html?highlight=conditionalprobdist#nltk.probability.ConditionalProbDist) with `probdist_factory`=`MLEProbDist`)\n",
    "\n",
    "Implement these steps in the cell below in a function `emission_model` that has one argument, `words`, containing a list of `(word, tag)` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:56:21.525078700Z",
     "start_time": "2024-02-01T15:56:21.508017800Z"
    }
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "def emission_model(words):\n",
    "    tuples = [(tag, word) for (word, tag) in words]\n",
    "    cfdist = ConditionalFreqDist(tuples)\n",
    "    cpdist = ConditionalProbDist(cfdist, probdist_factory=MLEProbDist)\n",
    "    return cpdist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2) Transition Model\n",
    "Given the tagged sentences, the main steps are:\n",
    "1. Create chain of tuples ($tag_{t}, tag_{t+1}$) to be passed to `ConditionalFreqDist()`. To achieve this efficiently:\n",
    "    * Create a generator expression (similar to list comprehension but replacing `[]` with `()` which iterates over each sentence and for each sentence creates a pair of ($tag_{t}, tag_{t+1}$) (if you are curious about generator expressions, you can read [this](https://wiki.python.org/moin/Generators) and [this](https://realpython.com/introduction-to-python-generators/))\n",
    "    * Create a chain from the ouput of the generator (hint: [itertools.chain.from_iterable()](https://docs.python.org/3.4/library/itertools.html#itertools.chain.from_iterable))\n",
    "2. Calculate the frequency of the next tag given the previous tag. (hint: [ConditionalFreqDist](https://www.nltk.org/api/nltk.html))\n",
    "3. Calculate the conditional probability distribution of the next tag given the previous tag. (hint: [ConditionalProbDist](https://www.nltk.org/api/nltk.html))\n",
    "\n",
    "Implement these steps in the cell below in a function `transition_model` that has one argument, `sentences`, containing the dataset of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:58:58.914296200Z",
     "start_time": "2024-02-01T15:58:58.895691Z"
    }
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "def transition_model(sentences):\n",
    "    tagGenerators = (((s[i][1], s[i+1][1]) for i in range(len(s) - 1)) for s in sentences)\n",
    "    data = itertools.chain.from_iterable(tagGenerators)\n",
    "    cfdist = ConditionalFreqDist(data)\n",
    "    cpdist = ConditionalProbDist(cfdist, probdist_factory=MLEProbDist)\n",
    "    \n",
    "    return cpdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilising the previously created models, the cell below trains the emission and transition models, the former using tagged words and the later on tagged sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:59:01.062081Z",
     "start_time": "2024-02-01T15:58:59.835116Z"
    }
   },
   "outputs": [],
   "source": [
    "emission_p = emission_model(train_tagged_words)\n",
    "transition_p = transition_model(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Brown corpus, the trained HMM gives the following probabilities:\n",
    "* The probability of observing the world `city` given the tag `NOUN`.\n",
    "* The probability of the tag `VERB` given the tag `NOUN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:00:12.745273900Z",
     "start_time": "2024-02-01T16:00:12.732233700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(city|NOUN) =  0.0009174311926605505\n",
      "p(VERB|NOUN) =  0.15875670429120206\n"
     ]
    }
   ],
   "source": [
    "p_city_NOUN = emission_p['NOUN'].prob('city')\n",
    "p_VERB_NOUN = transition_p['NOUN'].prob('VERB')\n",
    "print('p(city|NOUN) = ', p_city_NOUN)\n",
    "print('p(VERB|NOUN) = ', p_VERB_NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Viterbi algorithm\n",
    "\n",
    "The goal of the Viterbi algorithm is to find the most likely sequence of hidden states for a given sequence of observations. Specifically, we will utilise the Viterbi algorithm to find the tags of a sequence of untagged sentences, known as $decoding$. \n",
    "The benefit of this algorithm comes from its ability to efficiently determine the most probable path amongst the exponentially many possibilities. Doing so, it can reduce the complexity from $O(N^T)$ to $O(NT)$ where $N$ is the total number of words and $T$ is the total number of tags.\n",
    "\n",
    "Your task is to implement Viterbi algorithm and perform HMM decoding.\n",
    "Complete the missing `to-do` lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:30:02.610875300Z",
     "start_time": "2024-02-01T16:30:02.586323600Z"
    }
   },
   "outputs": [],
   "source": [
    "def viterbi(observed_seq, states, start_p, transition_p, emit_p):\n",
    "    eps = 0.00000001\n",
    "    \n",
    "    # Initialise the list, V, that will contain a dictionary for each element in the sequence. Each dictionary \n",
    "    # has the possible states (tags) as keys and its values are a dictionary with the keys:\n",
    "    # 'prob': the probability of the sequence until this point\n",
    "    # 'prev': the previous state used for backtracking.\n",
    "    V = [dict()] \n",
    "    for state in states:\n",
    "        # Compute the probability of each possible state for the first token in the sequence.\n",
    "        V[0][state] = {\"prob\": start_p[state] * emit_p[state].prob(observed_seq[0]), \"prev\": None}\n",
    "\n",
    "    # Run Viterbi for t > 0\n",
    "    for t in range(1, len(observed_seq)):\n",
    "        V.append({})\n",
    "        for state in states:\n",
    "            # In the forward pass, for each element of the observed_seq we want to store the maximum \n",
    "            # probability for each state as well as the previous state. This probability is the product of\n",
    "            # the maximum transition probability and the emission probability.\n",
    "            \n",
    "            # First we calculate the max_transition_prob by going through all the combinations between states.\n",
    "            # The next line just initialises the max_transition_prob:\n",
    "            max_transition_prob = 0.0\n",
    "            \n",
    "            for prev_state in states:\n",
    "                # Next, we calculate each possible transition probability that results in tag_t = state.\n",
    "                # The transition probability is given by the product between\n",
    "                # the prob of the sequence until t-1 where tag_{t-1} = prev_state,\n",
    "                # and the transition probability from prev_state to state.\n",
    "                transition_prob = V[t-1][prev_state]['prob'] * transition_p[prev_state].prob(state)\n",
    "                \n",
    "                #update the maximum transition_prob accordingly\n",
    "                if transition_prob > max_transition_prob:\n",
    "                    max_transition_prob = transition_prob\n",
    "                    prev_state_selected = prev_state\n",
    "                    \n",
    "            # Calculate the max_prob given by the product of the maximum transition probability and the \n",
    "            # emission probability. Remember to add eps to each probability before multiplying them together\n",
    "            max_prob = (max_transition_prob + eps) * (emit_p[state].prob(observed_seq[t]) + eps)\n",
    "            \n",
    "            V[t][state] = {\"prob\": max_prob, \"prev\": prev_state_selected}\n",
    "\n",
    "    most_likely_seq = []\n",
    "    max_prob = 0.0\n",
    "    previous = None\n",
    "    # Get most probable final state before backtracking\n",
    "    for state, data in V[-1].items():\n",
    "        if data[\"prob\"] > max_prob:\n",
    "            max_prob = data[\"prob\"]\n",
    "            best_state = state\n",
    "    most_likely_seq.append(best_state)\n",
    "    previous = best_state\n",
    "\n",
    "    # Backtrack until the first observation\n",
    "    for t in range(len(V) - 2, -1, -1):\n",
    "        # add the most likely tag to the most_likely_seq. Remember: we are backtracking hence we need to \n",
    "        # add before the last tag (hint: most_likely_seq.insert() )\n",
    "        most_likely_seq.insert(0, V[t + 1][previous][\"prev\"])\n",
    "        \n",
    "        previous = V[t + 1][previous][\"prev\"]\n",
    "\n",
    "    # print ('The steps of states are ' + ' '.join(most_likely_seq) + ' with highest probability of %s' % max_prob)\n",
    "\n",
    "    return list(zip(observed_seq, most_likely_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to get `n=10` random sentences as test data (untagged words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:30:03.873520700Z",
     "start_time": "2024-02-01T16:30:03.853431700Z"
    }
   },
   "outputs": [],
   "source": [
    "import random, time\n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    "\n",
    "n = 10\n",
    "# n = 11468 # whole test set\n",
    "# choose random n numbers\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(n)]\n",
    "\n",
    "# list of 10 sentences on which we test the model\n",
    "test_run = [test_set[i] for i in rndom]\n",
    " \n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    " \n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to check your implementation of the Viterbi algorithm on the test set and its POS tagging accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:30:04.765679300Z",
     "start_time": "2024-02-01T16:30:04.660791200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  0.009031057357788086\n",
      "Viterbi Algorithm Accuracy:  97.05882352941177\n"
     ]
    }
   ],
   "source": [
    "possible_tags = list(set([pair[1] for pair in train_tagged_words]))\n",
    "start_pr = {}\n",
    "for tag in possible_tags:\n",
    "    start_pr[tag] = 1.0/len(possible_tags)\n",
    "    \n",
    "start = time.time()\n",
    "predicted_tags = viterbi(test_tagged_words, possible_tags, start_pr, transition_p, emission_p)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy \n",
    "predicted_correct = [i for i, j in zip(predicted_tags, test_run_base) if i == j]  \n",
    "\n",
    "accuracy = len(predicted_correct)/len(predicted_tags)\n",
    "print('Viterbi Algorithm Accuracy: ', accuracy*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the print the first 10 words and their predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:30:06.446126600Z",
     "start_time": "2024-02-01T16:30:06.426261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('I', 'PRON'),\n ('forced', 'VERB'),\n ('confidence', 'NOUN'),\n ('into', 'ADP'),\n ('myself', 'PRON'),\n ('.', '.'),\n ('Falling', 'VERB'),\n ('somewhere', 'ADV'),\n ('in', 'ADP'),\n ('a', 'DET')]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tags[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the mispredicted tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T16:30:07.537149600Z",
     "start_time": "2024-02-01T16:30:07.527122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('undeniably', 'VERB') ('undeniably', 'ADV')\n",
      "('there', 'PRT') ('there', 'ADV')\n",
      "('that', 'PRON') ('that', 'DET')\n",
      "('wetly', 'NOUN') ('wetly', 'ADV')\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(predicted_tags, test_run_base):\n",
    "    if i != j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the model predict? Can you make any observations regarding the wrongly-predicted tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Robot localisation -- Optional\n",
    "\n",
    "Another application of HMM application is robot localisation, which is the focus of this exercise. \n",
    "\n",
    "We have a robot which is deployed to Mars to collect some samples. However, during the landing phase, the connection got temporarily lost and we are not sure where exactly the robot is. Luckily, the map of the area is available and the robot is provided with a sensor that can detect rocky surface.\n",
    "\n",
    "The aim is to utilised HMM to localise the robot where the hidden variable $z$ is the position of the robot and the observation $x$ is given by the sensor measurement. \n",
    "The figure at the top of the lab sheet, taken from Bishop, shows the relation between hidden variables $z$ with the observable variables $x$.  \n",
    "\n",
    "We will achieve this through the discrete case of the Bayes Filter which consists of mainly two steps:\n",
    "prediction step and measurement step. Your task will be to implement these two steps which is given by the following pseudocode.\n",
    "\n",
    "First step:\n",
    "$$ \\overline{p}_{k,t} = \\sum_i p(z_k | u_t, z_i) p_{i, t-1} $$\n",
    "where:\n",
    "* $\\overline{p}_{k,t}$: the predicted belief of the new state $z_k$ at the current time $t$ based on the action (control $u_t$). \n",
    "* $p_{i, t-1}$: the belief of state $z_i$ at the previous time step $t_1$\n",
    "* $p(z_k | u_t, z_i)$ : the transition probability of moving from state $z_i$ to state $z_k$ when taking action $u_t$.\n",
    "\n",
    "In the second step, the knowledge from the measurement model $p(x_t | z_k)$ is combined with the predicted belief $\\overline{p}_{k,t}$ to obtain the posterior belief $p_{i, t-1}$ of each state. This posterior belief becomes the current belief for the next time step.\n",
    "\n",
    "$$ p_{i, t} = \\eta p(x_t | z_k) \\overline{p}_{k,t}  $$\n",
    "$p(x_t | z_k)$ is also known as the likelihood, i.e. how likely it is to see an observation given the robot is in location $z_k$. We need to get the likelihood before implementing the belief. Moreover $\\eta$ is the normalising term such that the probability adds to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the implementation of both World and Robot class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.194821200Z"
    }
   },
   "outputs": [],
   "source": [
    "class World():\n",
    "    def __init__(self,start=(0,0),N=15):\n",
    "        self.world = np.zeros((N,N))\n",
    "        self.world[0,:] = 1\n",
    "        self.world[-1,:] = 1\n",
    "        self.world[:,0] = 1\n",
    "        self.world[:,-1] = 1\n",
    "        self.world[5, 6:12] = 1\n",
    "        self.world[6:11, 9] = 1\n",
    "        self.world[7:10, 6] = 1\n",
    "        self.world[11, 4:10] = 1\n",
    "        self.N = N\n",
    "    \n",
    "    def get_world(self):\n",
    "        return self.world\n",
    "    def set_world(self,N):\n",
    "        self.world = np.zeros((N,N))\n",
    "    def show_world(self):\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=1)\n",
    "        ax.set_xticks(np.arange(-.5, self.N, 1));\n",
    "        ax.set_yticks(np.arange(-.5, self.N, 1));\n",
    "#         ax.axis('off')\n",
    "        im = ax.imshow(self.world)\n",
    "        plt.colorbar(im)\n",
    "        plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robot has 4 possible actions: up, down, left and right. Each action will transition the robot in the new state with probability `p_move`. At each state the robot can measure whether the surface is rocky or normal by calling `measurement()` with the sensor's noise value of `p_sense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T15:37:30.201837800Z",
     "start_time": "2024-02-01T15:37:30.196821700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Robot:\n",
    "    def __init__(self, p_move, p_sense, world):\n",
    "        self.location = np.random.randint(0,world.shape[0],2)\n",
    "        self.p_move = p_move\n",
    "        self.p_sense = p_sense\n",
    "        self.world =  world\n",
    "        self.N = self.world.shape[0]\n",
    "        self.possibleActions = ['U', 'D', 'L', 'R']\n",
    "        self.tracking_error = []\n",
    "        self.homing_error = []\n",
    "\n",
    "    # The robot transition are noisy with prob_move to follow the action and (1-p_move) of staying\n",
    "    # in the same location\n",
    "    def transition(self,action):\n",
    "        if (np.random.rand() < self.p_move):\n",
    "            if(action == 'U' ):\n",
    "                self.location =  (max(0,self.location[0]-1), self.location[1])\n",
    "            elif(action == 'R'):\n",
    "                self.location = (self.location[0], min(self.N-1,self.location[1]+1))\n",
    "            elif(action == 'D'):\n",
    "                self.location = (min(self.N-1,self.location[0]+1), self.location[1])\n",
    "            elif(action == 'L'):\n",
    "                self.location = (self.location[0], max(0,self.location[1]-1))\n",
    "            \n",
    "        return self.location\n",
    "\n",
    "    # Measurement model which returns 1 when the surface is rocky and 0 otherwise.\n",
    "    # As in transition model, the sensor can be noisy with p_sense of returning the correct value.\n",
    "    def measurement(self):\n",
    "        if (np.random.rand() < self.p_sense):\n",
    "            return self.world[int(self.location[0]),int(self.location[1])]\n",
    "        else:\n",
    "            if self.world[int(self.location[0]),int(self.location[1])] == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    # transition model of the robot assuming no noise\n",
    "    def transition_no_noise(self,location,action):\n",
    "        if(action == 'U' ):\n",
    "            location =  (max(0,location[0]-1), location[1])\n",
    "        elif(action == 'R'):\n",
    "            location = (location[0], min(self.N-1,location[1]+1))\n",
    "        elif(action == 'D'):\n",
    "            location = (min(self.N-1,location[0]+1), location[1])\n",
    "        elif(action == 'L'):\n",
    "            location = (location[0], max(0,location[1]-1))\n",
    "            \n",
    "        return location\n",
    "\n",
    "    def visualise_true_position(self):\n",
    "        x = self.world.copy()\n",
    "        x[int(self.location[0]),int(self.location[1])] = 0.5\n",
    "#         x[int(self.home[0]),int(self.home[1])] = 0.7\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map is discrete and represented through grids where each grid indicates a position. \n",
    "As displayed below, the yellow corresponds to the rocky surface while the purple corresponds to the normal surface. The sensor measurement will output a value of 1 for the rocky surface and a value of 0 for the normal surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.197823Z"
    }
   },
   "outputs": [],
   "source": [
    "world = World(15)\n",
    "world.show_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells to initialise the robot class and show the starting position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.199325Z"
    }
   },
   "outputs": [],
   "source": [
    "p_move = .9  # original value 0.9\n",
    "p_sense = .8 # original value 0.8\n",
    "N = 15\n",
    "# Initialise belief in position - uniform distribution over world\n",
    "state_belief = np.ones((N,N))/(N*N)\n",
    "\n",
    "robot = Robot(p_move,p_sense,world.get_world())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.199325Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(robot.visualise_true_position());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell provides helper functions to visualise the true robot position, the predicted belief, the likelihood and the posterior belief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.200831Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to visualise \n",
    "def show(robot, predicted_state_belief, likelihood, state_belief):\n",
    "    plt.clf()\n",
    "    plt.subplot(2,4,1)\n",
    "    plt.cla()\n",
    "    plt.imshow(robot.visualise_true_position())\n",
    "    plt.title('True position in world')\n",
    "    \n",
    "    plt.subplot(2,4,2)\n",
    "    plt.cla()\n",
    "    plt.imshow(predicted_state_belief)\n",
    "    plt.title('Predicted belief given action')\n",
    "    \n",
    "    plt.subplot(2,4,3)\n",
    "    plt.cla()\n",
    "    plt.imshow(likelihood)\n",
    "    plt.title('Likelihood')\n",
    "    \n",
    "    plt.subplot(2,4,4)\n",
    "    plt.cla()\n",
    "    plt.imshow(state_belief)\n",
    "    plt.title('Posterior belief given measurement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains the main algorithm and your task is to fill the missing lines `to-do` (hint: check the provided pseudocode above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-02-01T15:37:30.201837800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the discrete Bayes filter\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "N = 15\n",
    "steps = 100\n",
    "# Create list of possible states in world (x,y coordinates)\n",
    "possible_states = np.array(np.meshgrid(np.linspace(0,N-1,N),np.linspace(0,N-1,N))).reshape(2,-1).T\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    # Sample a random action\n",
    "    a = np.random.choice(['U','D','L','R'])\n",
    "    \n",
    "    # Move the robot according to the action and sense the measurement\n",
    "    state = robot.transition(a)\n",
    "    measurement = robot.measurement()\n",
    "    \n",
    "    # Make prediction about state belief given action\n",
    "    predicted_state_belief = np.zeros((N,N))\n",
    "    \n",
    "    for state in possible_states.astype(int):\n",
    "        \n",
    "        new_state = robot.transition_no_noise(state,a)\n",
    "        \n",
    "        predicted_state_belief[state[0],state[1]] = # TO-DO\n",
    "   \n",
    "    # Evaluate sensor belief for each possible state\n",
    "    likelihood = np.zeros((N,N))\n",
    "    for state in possible_states.astype(int):\n",
    "        \n",
    "        match = measurement == world.get_world()[state[0],state[1]]\n",
    "        likelihood[state[0],state[1]] = # TO-DO\n",
    "    \n",
    "    # Compute posterior belief over possible states\n",
    "    state_belief = # TO-DO\n",
    "    \n",
    "    # normalising\n",
    "    state_belief = (state_belief+1e-15)\n",
    "    state_belief = state_belief/np.sum(state_belief) \n",
    "    \n",
    "    # Make a function to display\n",
    "    show(robot, predicted_state_belief, likelihood, state_belief)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the `p_move` and `p_sense` values and re-run the experiment with different values. How these probabilities affect the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this lab. Let's summarise what we have learnt:\n",
    "* Understand the role of the HMM components \n",
    "* Key applications of HMM such as POS tagger\n",
    "* Perform POS tagging through the transition model and the emission model.\n",
    "* Implemented the Viterbi algorithm and the discrete Bayes filter algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* COMS30035 Machine Learning\n",
    "* Bishop - Pattern Recognition and Machine Learning: Chapter 13 - Sequential Data\n",
    "* [Probabilistic Robotics](http://www.probabilistic-robotics.org) \n",
    "* University of Edinburgh's Foundations of Natural Language Processing (FNLP) and Decision Making in Robots and Autonomous Agents (DMR) courses\n",
    "* [Hussain Mujtaba](https://www.mygreatlearning.com/blog/pos-tagging/)\n",
    "* [Neuromatch Academy 2020](https://www.neuromatchacademy.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End :)\n",
    "\n",
    "<video controls src=\"gif.mp4\" width=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
